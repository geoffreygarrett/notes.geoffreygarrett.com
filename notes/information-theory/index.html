<!DOCTYPE html>
<html lang="en">
<head>
  
  <meta charset="UTF-8" />
  <meta
    name="description"
    content="Self-information (information content) The self-information (a.k.a. information content, surprisal, or Shannon information) is a quantity used in information theory which is derived from the probability of a certain event occurring from a random variable."
  />
  <meta name="viewport" content="width=device-width, initial-scale=1"><link rel='stylesheet' href='https://cdn.jsdelivr.net/gh/alphardex/aqua.css/dist/aqua.min.css'>
  <title>
    Information Theory
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link
    rel="shortcut icon"
    type="image/png"
    href="https://notes.geoffreygarrett.com//icon.png"
  />

  
  <link
    href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap"
    rel="stylesheet"
  />
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <link href="https://notes.geoffreygarrett.com/styles.9401185f72df0629fa45598ee5df1c40.css" rel="stylesheet" />

  
  <script src="https://notes.geoffreygarrett.com/js/darkmode.d2f0ee97155fcdb9fc2b573dfd2ba98d.min.js"></script>
  
<link rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
      integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs"
      crossorigin="anonymous">
<link href="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/copy-tex.css"
      rel="stylesheet" type="text/css">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
        integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
        crossorigin="anonymous"></script>
<script defer
        src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
        integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/copy-tex.min.js"
        integrity="sha384-Ep9Es0VCjVn9dFeaN2uQxgGcGmG+pfZ4eBaHxUpxXDORrrVACZVOpywyzvFRGbmv"
        crossorigin="anonymous"></script>



  
  <script src="https://notes.geoffreygarrett.com/js/popover.688c5dcb89a57776d7f1cbeaf6f7c44b.min.js"></script>

  
   
  <script>
    const BASE_URL = "https://notes.geoffreygarrett.com/"
    const fetchData = Promise.all([
          fetch("https:\/\/notes.geoffreygarrett.com\/indices\/linkIndex.a14d918100a04df44c9c95d70ca25299.json")
            .then(data => data.json())
            .then(data => ({
              index: data.index,
              links: data.links,
            })),
          fetch("https:\/\/notes.geoffreygarrett.com\/indices\/contentIndex.49fc651acc42913051b9fc7d53447224.min.json")
            .then(data => data.json()),
        ])
        .then(([{index, links}, content]) => ({
          index,
          links,
          content,
        }))

    const draw = () => {
      const container = document.getElementById("graph-container")
      
      if (!container) return requestAnimationFrame(draw)
      
      container.textContent = ""

      drawGraph(
        "https://notes.geoffreygarrett.com",
        [{"/moc":"#4388cc"}],
         -1 ,
         true ,
         false ,
         true 
      );

      
      initPopover(
        "https://notes.geoffreygarrett.com",
         true ,
         true 
      )
      
      
      renderMathInElement(document.body, {
        delimiters: [
          {left: '$$', right: '$$', display: true},
          {left: '$', right: '$', display: false},
        ],
        throwOnError : false
      });
      
    };
  </script>
  
  
  <script type="module">
    import { attachSPARouting } from 'https:\/\/notes.geoffreygarrett.com\/js\/router.88d6def7f687fe498bfc6de6c16d554b.min.js';
    
    attachSPARouting(draw);
  </script>
  
</head>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-1RCSBZMTSN"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-1RCSBZMTSN', { 'anonymize_ip': false });
}
</script>



<body>
<div id="search-container">
    <div id="search-space">
        <input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search" placeholder="Search for something...">
        <div id="results-container">
        </div>
    </div>
</div>
<script src="https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js" integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin="anonymous" defer></script>

<script defer src="https://notes.geoffreygarrett.com/js/search.06935f6a9c1dd79aa33fe3a725067dbc.js"></script>

<div class="singlePage">
    
    <header>
        <h1 id="page-title"><a href="https://notes.geoffreygarrett.com/">Geoffrey&#39;s Notes</a></h1>
      <svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg>
      <div class="spacer"></div>
      <div class='darkmode'>
    <input class='toggle' id='darkmode-toggle' type='checkbox' tabindex="-1">
    <label id="toggle-label-light" for='darkmode-toggle' tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35;" xml:space="preserve">
            <title>Light Mode</title>
            <path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z" />
        </svg>
    </label>
    <label id="toggle-label-dark" for='darkmode-toggle' tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'" xml:space="preserve">
            <title>Dark Mode</title>
            <path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z" />
        </svg>
    </label>
</div>
  </header>
  <article>
      <h1>Information Theory</h1>
      <p class="meta">
          Last updated May 31, 2022
      </p>
      <ul class="tags">
          
      </ul>
      
<aside class="mainTOC">
    <details >
        <summary>Table of Contents</summary>
        <nav id="TableOfContents">
  <ol>
    <li><a href="#self-information-information-content">Self-information (information content)</a></li>
    <li><a href="#entropy-average-information">Entropy (average information)</a></li>
    <li><a href="#kullback-leibler-divergence-information-gain">Kullback-Leibler divergence (information gain)</a></li>
    <li><a href="#jensen-shannon-divergence-information-radius">Jensen-Shannon divergence (information radius)</a></li>
  </ol>
</nav>
    </details>
</aside>


      






  
  

  
  

  
  

  
  

  
  

  
  












<a href="#self-information-information-content"><h2 id="self-information-information-content"><span class="hanchor" ariaLabel="Anchor"># </span>Self-information (information content)</h2></a>
<p>The self-information (a.k.a. <em>information content</em>, <em>surprisal</em>,
or <em>Shannon information</em>) is a quantity used in information theory which
is derived from the probability of a certain event occurring from a random
variable. The self-information was defined by Claude Shannon such that
the following axioms were met:</p>
<ul>
<li>An event that is 100% probable is perfectly unsurprising and
therefore yields no information content.</li>
<li>The less probable an event is, the more surprising, and therefore the
more information it yields.</li>
<li>The total information of independently measured events, is the
sum of their respective self-information.</li>
</ul>
<p>$$
\begin{equation}
I(x):=-\log_b(p(x))
\end{equation}
$$</p>
<a href="#entropy-average-information"><h2 id="entropy-average-information"><span class="hanchor" ariaLabel="Anchor"># </span>Entropy (average information)</h2></a>
<p>$$
\begin{equation}
H(x)=\mathbb{E}[I(x)]
\end{equation}
$$</p>
<a href="#kullback-leibler-divergence-information-gain"><h2 id="kullback-leibler-divergence-information-gain"><span class="hanchor" ariaLabel="Anchor"># </span>Kullback-Leibler divergence (information gain)</h2></a>
<p>The Kullback-Leibler divergence (a.k.a. <em>relative entropy</em> and
<em>I-divergence</em>) a measure of how one probability distribution $P$ differs
from another, $Q$. For the distributions $P$ and $Q$ for a continuous random
variable, the relative entropy integral is:</p>
<p>$$
\begin{equation}
D_{KL}(P||Q) = \int_{-\infty}^{\infty}p(x)\log\bigg(\frac{p(x)}{q(x)}\bigg)dx.
\end{equation}
$$</p>
<p>Note that $D_{KL}(P||Q)$ is only finite if the support set of $P$ is
contained in the support set of $Q$. In the context of Bayesian inference
$D_{KL}(P||Q)$, read as <em>the KL-divergence of P given Q</em>, is a
measure of the information gained by revisiting one&rsquo;s beliefs from a prior
probability distribution $Q$ to a posterior probability distribution $P$. For
example the $D_{KL}(P||Q)$ for $P\sim{}\mathcal{N}(\mu_1,\sigma_1)$ and
$Q\sim{}\mathcal{N}(\mu_2,\sigma_2)$ can be derived analytically to be:</p>
<p>$$
\begin{equation}
D_{KL}(P||Q) = \log\frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1-\mu_2)^2}{2\sigma_2^2} - \frac{1}{2}.
\end{equation}
$$</p>
<p>One noteworthy characteristic of the KL-divergence is its asymmetry, that is
$D_{KL}(P||Q)\neq{}D_{KL}(Q||P)$. This means that KL-divergence makes
for a poor <em>distance</em> metric as is commonly done with, for example,
squared-errors. This may at first present KL-divergence as a suboptimal choice
as a general metric, however when considering the relation between the posterior
and the priori, the relative information gain when travelling from one to the
other <strong>is</strong> inherently asymmetric by their very nature.</p>
<a href="#jensen-shannon-divergence-information-radius"><h2 id="jensen-shannon-divergence-information-radius"><span class="hanchor" ariaLabel="Anchor"># </span>Jensen-Shannon divergence (information radius)</h2></a>
<p>The Jensen-Shannon divergence (a.k.a. <em>information radius</em> and <em>total divergence
to the average</em>) is based on the KL-divergence, however it has been extended
with the differences that it is symmetric, and always has a finite value.</p>
<p>$$
\begin{equation}
D_{JS}(P||Q) = \frac{1}{2}D_{KL}(P||M) + \frac{1}{2}D_{KL}(Q||M)
\end{equation}
$$
$$
\text{where  }
M = \frac{1}{2}(P+Q)
$$</p>


    </article>
    <hr/>
<div class="page-end">
    <div class="backlinks-container">
        <h3>Backlinks</h3>
<ul class="backlinks">
    
    
    
    
    
    
    
    
    
      
      
      
    
      
      
      <li>
        <a href="/" data-ctx="Information Theory MOC" data-src="/" class="internal-link">Geoffrey&#39;s Notes</a>
      </li>
      
      
      
</ul>

    </div>
    <div>
        <script
  src="https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js"
  integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI="
  crossorigin="anonymous"
></script>
<h3>Interactive Graph</h3>
<div id="graph-container"></div>
<style>
  :root {
    --g-node: var(--secondary);
    --g-node-active: var(--primary);
    --g-node-inactive: var(--visited);
    --g-link: var(--outlinegray);
    --g-link-active: #5a7282;
  }
</style>

<script src="https://notes.geoffreygarrett.com/js/graph.0eb0c81d58a703569f31b6053242af38.js"></script>

    </div>
</div>




<div id="contact_buttons">
    <footer>
        <p>Made by Geoffrey Garrett using <a href="https://github.com/jackyzha0/quartz">Quartz</a>, Â© 2022</p>
        <ul>
            
            <li><a href="/">Home</a></li>
            <li><a href="https://twitter.com/GarrettHGeoff">Twitter</a></li><li><a href="https://github.com/geoffreygarrett">GitHub</a></li></ul>
    </footer>
</div>

</div>
</body>

</html>
