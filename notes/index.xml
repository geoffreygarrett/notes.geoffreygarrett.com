<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes on </title>
    <link>https://notes.geoffreygarrett.com/notes/</link>
    <description>Recent content in Notes on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://notes.geoffreygarrett.com/notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Concept Definitions</title>
      <link>https://notes.geoffreygarrett.com/notes/concept-definitions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/concept-definitions/</guid>
      <description>A dynamic collection of concept definitions which are either relevant to my work or are of interest to me. These definitions may be referred to from other parts of my notes.</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>https://notes.geoffreygarrett.com/notes/deep-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/deep-learning/</guid>
      <description>Deep Learning (DL) is a field of Machine Learning (ML) that is primarily concerned with the learning of representations of data.</description>
    </item>
    
    <item>
      <title>Estimation Theory</title>
      <link>https://notes.geoffreygarrett.com/notes/estimation-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/estimation-theory/</guid>
      <description>Estimation theory is a branch of statistics that addresses the estimation of unknown parameters based on empirical measurements, which contain a random component.</description>
    </item>
    
    <item>
      <title>Information Theory</title>
      <link>https://notes.geoffreygarrett.com/notes/information-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/information-theory/</guid>
      <description>Self-information (information content) The self-information (a.k.a. information content, surprisal, or Shannon information) is a quantity used in information theory which is derived from the probability of a certain event occurring from a random variable.</description>
    </item>
    
    <item>
      <title>Kalman Filter</title>
      <link>https://notes.geoffreygarrett.com/notes/kalman-filter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/kalman-filter/</guid>
      <description>Linearised Kalman Filter Extended Kalman Filter   Hidden Markov model  Unscented Kalman Filter $$ \begin{equation} \begin{aligned} L &amp;amp;= \text{dim}(\bm{x}) &amp;amp;&amp;amp; \bm{x}\in{\mathbb{R}}^{L} \ \mathcal{X}_0 &amp;amp;= \bm{x}_i^- &amp;amp;&amp;amp; k=1,&amp;hellip;,L \ \mathcal{X}_k &amp;amp;= \bm{x}_i^- + \bigg(\sqrt{(L+\lambda)\bm{P}_i^-}\bigg)_k &amp;amp;&amp;amp; k=1,&amp;hellip;,L \ \mathcal{X}_k &amp;amp;= \bm{x}_i^- + \bigg(\sqrt{(L+\lambda)\bm{P}_i^-}\bigg) _{k-L} &amp;amp;&amp;amp; k=L+1,&amp;hellip;,2L \ W_0^{(m)} &amp;amp;= \lambda(L-\lambda) \ W_0^{(m)} &amp;amp;= \lambda(L-\lambda) + (1-\alpha^2 + \beta) \ W_k^{(m)} &amp;amp;= W_k^{(c)} = 1/{2(L+\lambda)} &amp;amp;&amp;amp; k=1,&amp;hellip;,2L \ \end{aligned} \end{equation} $$</description>
    </item>
    
    <item>
      <title>Least Squares</title>
      <link>https://notes.geoffreygarrett.com/notes/least-squares/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/least-squares/</guid>
      <description>The least-squares method was officially discovered and published by Adrien-Marie Legendre in their work &amp;ldquo;Nouvelles methodes pour la determination des orbites des cometes&amp;rdquo;, published in 1805 [citation needed].</description>
    </item>
    
    <item>
      <title>Machine Learning</title>
      <link>https://notes.geoffreygarrett.com/notes/machine-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/machine-learning/</guid>
      <description>Sub-fields   Deep Learning  </description>
    </item>
    
    <item>
      <title>Markov Models</title>
      <link>https://notes.geoffreygarrett.com/notes/markov-models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/markov-models/</guid>
      <description>Characterization Fully Observable Partially Observable     Autonomous Markov chain/ process Hidden Markov model   Controlled Markov decision process</description>
    </item>
    
    <item>
      <title>Orbit Determination and Parameter Estimation</title>
      <link>https://notes.geoffreygarrett.com/notes/orbit-determination/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/orbit-determination/</guid>
      <description>Predicting the state ($\bm{x}_t$) of a spacecraft given an initial condition ($\bm{x}_0$), and models which form the equations of motion of the satellite, ($\dot{\bm{x}}=f(t,\bm{x})$), is a straightforward task involving the solution of an initial value problem (IVP) in the form of an ordinary differential equation (ODE).</description>
    </item>
    
    <item>
      <title>Software Engineering</title>
      <link>https://notes.geoffreygarrett.com/notes/software-engineering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/software-engineering/</guid>
      <description>  SOLID Principles  </description>
    </item>
    
    <item>
      <title>SOLID Principles</title>
      <link>https://notes.geoffreygarrett.com/notes/solid-principles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://notes.geoffreygarrett.com/notes/solid-principles/</guid>
      <description>In software engineering, SOLID is a mnemonic acronym for five design principles intended to make object-oriented designs more understandable, flexible, and maintainable.</description>
    </item>
    
  </channel>
</rss>
