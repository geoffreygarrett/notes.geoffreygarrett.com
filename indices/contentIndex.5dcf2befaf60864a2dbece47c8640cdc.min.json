{"/":{"title":"Geoffrey's Notes","content":"\n## Maps of Content üó∫Ô∏è\n\nHere are the current maps to my notes. What you see here will change overtime.\nThey won't disappear, they might just be reshuffled and organised under new maps\nthat I deem necessary to add at a later time. For example, I currently have the\nmaps of [software engineering](public/software-engineering.md) and [machine\nlearning](public/machine-learning.md) present, with some [machine learning\nalgorithms](public/dbscan.md) in [software\nengineering](public/software-engineering.md), both of which _may_ later be\nfound under **computer science**. Feel free to peruse, some notes may have\ncomments enabled if I feel that a note is well-developed enough.\n\n- [Linear Algebra MOC](public/linear-algebra.md)\n- [Estimation Theory MOC](public/estimation-theory.md)\n- [Information Theory MOC](public/information-theory.md)\n- [Software Engineering MOC](public/software-engineering.md)\n- [Machine Learning MOC](public/machine-learning.md)\n\n## Useful üõ†Ô∏è\n\nThis section is a general catch-all for anything I feel I want to keep visible\non the surface. They might help me organise my thoughts in the long-term, or\nlookup information and resources that I desire at my fingertips.\n\n- [Concept Definitions](public/concept-definitions.md)\n- [Writing Guide](https://salman.io/public/writing/)\n- [Reflection on two years of writing evergreen notes: not optimal for skill acquisition and learning](https://engineeringideas.substack.com/p/reflection-on-two-years-of-writing)\n- [All Notes](/public)\n\n## Types of Notes ‚ÑπÔ∏è\n\nAs I pursue tending to my digital garden, with new additions, or modifications\nto existing parts, you can expect me to (loosely) follow a (hopefully)\nconsistent categorisation described by the following:\n\n- üå∞ A **Seed** might just be a note, link or some thought. Perhaps a\n  placeholder for something I'd like to pursue later. These may be linked or\n  unlinked, perhaps hidden away where no one sees them.\n- üå± A **Seedling** is more established and ready to continue growing. It has \n  some weak parts, but it's getting there with time. Ideally it won't stay \n  a seedling for much longer, it just needs a bit of tending, water and sunshine.\n- üå≤ An **Evergreen** has finished growing. It could do with some pruning once\n  in a while throughout the seasons, but it's mature and isn't expected to\n  disappear in our lifetime.\n","lastmodified":"2022-06-29T09:30:38.948112687Z","tags":null},"/public/cholesky-decomposition":{"title":"Cholesky Decomposition","content":"\nCholesky Decomposition (_a.k.a. Cholesky factorisation_) is a method of \ndecomposing a _positive semidefinite matrix_ into a lower triangular matrix.","lastmodified":"2022-06-29T09:30:38.948112687Z","tags":null},"/public/concept-definitions":{"title":"Concept Definitions","content":"\nA dynamic collection of concept definitions which are either relevant to my work\nor are of interest to me. These definitions may be referred to from other\nparts of my notes. \n\n## _\"A priori\"_ and _\"a posteriori\"_\n\n\u003e _‚ÄúA priori‚Äù and ‚Äúa posteriori‚Äù refer primarily to how, or on what basis, a\nproposition might be known. In general terms, a proposition is knowable a priori\nif it is knowable independently of experience, while a proposition knowable a\nposteriori is knowable on the basis of experience. The distinction between a\npriori and a posteriori knowledge thus broadly corresponds to the distinction\nbetween empirical and nonempirical knowledge._ - [Internet Encyclopedia of\nPhilosophy](https://iep.utm.edu/apriori/)\n\n- [Further reading](https://en.wikipedia.org/wiki/A_priori_and_a_posteriori)","lastmodified":"2022-06-29T09:30:38.948112687Z","tags":null},"/public/conda":{"title":"","content":"\n\n## Activate environment in `bash`\n\n```bash\neval \"$(conda shell.bash hook)\"\nconda activate \u003cenv-name\u003e\n```\n\nOtherwise:\n```bash\nsource ~/anaconda3/etc/profile.d/conda.sh\nconda activate \u003cenv-name\u003e\n```","lastmodified":"2022-06-29T09:30:38.948112687Z","tags":null},"/public/css":{"title":"CSS","content":"\nCascading style sheets (CSS) \n\n## Loose Links\n- [min(), max(), and clamp(): three logical CSS functions to use today](https://web.dev/min-max-clamp/)","lastmodified":"2022-06-29T09:30:38.948112687Z","tags":null},"/public/data-sampling-methods":{"title":"Data Sampling Methods","content":"\n## Stochastic Methods\n\n## Deterministic Methods\n\n### Low discrepancy\n\n### Experimental design methods\n\n## Geometric Methods\n\n### Uniform grid\n\n### Latin hypercube\n\n### Centroidal Voronoi Tesellation\n\n### Opposite methods\n\n## Hybrid methods\n\n## Sampling non-uniform distributions\n\n## Importance sampling\n\n## Bibliography\n\n{{\u003c rawhtml \u003e}}\n \u003cul\u003e\n  \u003cli\u003e\n\u003ca href=\"https://www.sciencedirect.com/science/article/pii/S0893608015001768\"\u003e\n\u003cdiv class=\"csl-entry\"\u003e Smart sampling and incremental function learning for\nvery large high dimensional data. (2016). \u003ci\u003eNeural Networks\u003c/i\u003e, \u003ci\u003e78\u003c/i\u003e,\n75‚Äì87. \u003c/div\u003e \u003c/a\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n{{\u003c /rawhtml \u003e}}\n\n- [How to evenly distribute points on a sphere more effectively than the canonical Fibonacci Lattice](http://extremelearning.com.au/how-to-evenly-distribute-points-on-a-sphere-more-effectively-than-the-canonical-fibonacci-lattice/)\n- [How to generate uniformly random points on n-spheres and in n-balls](http://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/)","lastmodified":"2022-06-29T09:30:38.948112687Z","tags":null},"/public/dbscan":{"title":"DBSCAN","content":"\nDensity-based spacial clustering of applications with noise (DBSCAN) is a [clustering algorithm](https://en.wikipedia.org/wiki/Cluster_analysis) proposed by Ester et al. in 1996. DBSCAN is one of the [most cited clustering\nalgorithms](https://web.archive.org/web/20100421170848/http://academic.research.microsoft.com/CSDirectory/paper_category_7.htm)\nin scientific literature.\n\n```bibtex {linenos=false}\n@inproceedings{Ester1996,\n   author = {Martin Ester and Hans-Peter Kriegel and J√∂rg Sander and Xiaowei Xu},\n   journal = {KDD},\n   title = {A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise},\n   year = {1996},\n}\n```\n\n## Resources\n\n- [How HDBSCAN Works](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)","lastmodified":"2022-06-29T09:30:38.948112687Z","tags":null},"/public/deep-learning":{"title":"Deep Learning","content":"\nDeep Learning (DL) is a field of Machine Learning (ML) that is primarily\nconcerned with the learning of representations of data. At the core of DL is the\nuse of Multi-layer perceptrons (MLPs), used to model these representations. MLPs\nare fully connected layers of biologically inspired artifical neurons, also\nknown as perceptrons. A brief history are these biologically inspired models are\ncovered in Section X with adapted notation from the field of DL. Although not\nall practices in DL, strictly speaking, make use of MLPs, they are a fundamental\nconcept which must be understood in the stepping stones towards concepts of\nhigher complexity in the field. Section X covers this concept, extending\ndirectly on their composite component: perceptrons.\n\n**MLP** are also called **feedfoward** as information is propagated in\nonly a forward direction, as opposed to exhibiting **feedback** connections,\nwhere intermediate computations are fed back into the network. When feedforward\nnetworks are extended to include feedback connections, they are called\n**RNNs**. These types of networks excel at learning temporal\nfeatures, exhibiting a refined hypothesis space favouring sequenced information,\nsuch as a series of chronological observations. Section X covers this\ntype of DNN, and the prominent sub-type of RNN: LSTMs.\n\nOne type of neural networks which is similar to MLP and popular in\ncontemporary research, is the CNN. These deep NN are essentially\nMLP which omit the property of being fully connected, in favour of\nrefining the hypothesis space towards detection of spatially-related features.","lastmodified":"2022-06-29T09:30:38.948112687Z","tags":null},"/public/estimation-theory":{"title":"Estimation Theory","content":"\n**Estimation theory** is a branch of statistics that addresses the estimation of\nunknown parameters based on empirical measurements, which contain a random\ncomponent.\n\n- An **estimator** is an algorithm that attempts to approximate the unknown\n  parameters using measurements.\n\n## Estimators \n\n- [Least squares](public/least-squares.md)\n- [Kalman filter](public/kalman-filter.md)\n\n## Applications\n\n- [Orbit determination](public/orbit-determination.md)\n","lastmodified":"2022-06-29T09:30:38.948112687Z","tags":null},"/public/information-theory":{"title":"Information Theory","content":"\n## Self-information\n\nThe self-information (a.k.a. _information content_, _surprisal_,\nor _Shannon information_) is a quantity used in information theory which\nis derived from the probability of a certain event occurring from a random\nvariable. The self-information was defined by Claude Shannon such that\nthe following axioms were met:\n\n- An event that is 100% probable is perfectly unsurprising and\n  therefore yields no information content.\n- The less probable an event is, the more surprising, and therefore the\n  more information it yields.\n- The total information of independently measured events, is the\n  sum of their respective self-information.\n\n$$\n\\begin{equation}\n    I(x):=-\\log_b(p(x))\n\\end{equation}\n$$\n\n## Entropy\n\n$$\n\\begin{equation}\n    H(x)=\\mathbb{E}[I(x)]\n\\end{equation}\n$$\n\n## Kullback-Leibler divergence\nThe Kullback-Leibler divergence (a.k.a. _information gain_, _relative entropy_\nand _I-divergence_) is a measure of how one probability distribution $P$ differs\nfrom another, $Q$. For the distributions $P$ and $Q$ for a continuous random\nvariable, the relative entropy integral is:\n\n$$\n\\begin{equation}\n    D_{KL}(P||Q) = \\int_{-\\infty}^{\\infty}p(x)\\log\\bigg(\\frac{p(x)}{q(x)}\\bigg)dx.\n\\end{equation}\n$$\n\nNote that $D_{KL}(P||Q)$ is only finite if the support set of $P$ is\ncontained in the support set of $Q$. In the context of Bayesian inference\n$D_{KL}(P||Q)$, read as _the KL-divergence of P given Q_, is a\nmeasure of the information gained by revisiting one's beliefs from a prior\nprobability distribution $Q$ to a posterior probability distribution $P$. For\nexample the $D_{KL}(P||Q)$ for $P\\sim{}\\mathcal{N}(\\mu_1,\\sigma_1)$ and\n$Q\\sim{}\\mathcal{N}(\\mu_2,\\sigma_2)$ can be derived analytically to be:\n\n$$\n\\begin{equation}\n    D_{KL}(P||Q) = \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma_1^2 + (\\mu_1-\\mu_2)^2}{2\\sigma_2^2} - \\frac{1}{2}.\n\\end{equation}\n$$\n\nOne noteworthy characteristic of the KL-divergence is its asymmetry, that is\n$D_{KL}(P||Q)\\neq{}D_{KL}(Q||P)$. This means that KL-divergence makes\nfor a poor _distance_ metric as is commonly done with, for example,\nsquared-errors. This may at first present KL-divergence as a suboptimal choice\nas a general metric, however when considering the relation between the posterior\nand the priori, the relative information gain when travelling from one to the\nother **is** inherently asymmetric by their very nature. \n\n## Jensen-Shannon divergence\n\nThe Jensen-Shannon divergence (a.k.a. _information radius_ and _total divergence\nto the average_) is based on the KL-divergence, however it has been extended\nwith the differences that it is symmetric, and always has a finite value.\n\n$$\n\\begin{equation}\n    D_{JS}(P||Q) = \\frac{1}{2}D_{KL}(P||M) + \\frac{1}{2}D_{KL}(Q||M)\n\\end{equation}\n$$\n$$\n\\text{where  }\nM = \\frac{1}{2}(P+Q)\n$$","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/javascript-dependencies":{"title":"Satisfying JavaScript Dependencies","content":"\n## [Content Delivery Network (CDN)](public/cdn.md)\n\n\n\n## Import Map\n\n## Node Package Manager (NPM)","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/jetbrains-environment":{"title":"JetBrains Environment","content":"\nThis note is a general collection of plugins for JetBrain's products which I use\non a daily basis. I will almost exclusively stick to free plugins with the\nexception of the [Material Theme\nUI](https://plugins.jetbrains.com/plugin/8006-material-theme-ui/) which I have\nyet to find a satisfactory alternative to. For the record, I used this plugin\nfor years prior to it becoming exclusive to those willing to add another **paid\nsubscription** to their financial commitments. I'm not happy about it, but I\nbecame dependent on it.\n\n## Wrap to column\n\n- [Plugin Page](https://plugins.jetbrains.com/plugin/7234-wrap-to-column)\n\nI cannot live without this plugin anymore. This plugin is Similar to the Emacs\ncommand 'Fill Paragraph' and Vim's `gq` (format lines) command. It's a great\ntool for formatting raw markdown and LaTeX to a consistent column width for\nreadability. After installing, the following keymappings are default.\n\n**Note**: This is the default for Linux \u0026 Windows, I don't personally know it\nfor macOS. See `File \u003e Settings` and search for \"Wrap to\" for your keybinding.\n\n| Keybinding         | Command                       |\n|--------------------|-------------------------------|\n| `Ctrl+Alt+Shift+W` | Wrap Line to Column           |\n| `Ctrl+Alt+Shift+P` | Wrap Paragraph to Column      |\n\n## Rainbow Brackets\n\n- [Plugin Page](https://plugins.jetbrains.com/plugin/10080-rainbow-brackets)\n\nA simple but highly effective plugin that adds a quality of life feature to\nJetBrains IDEs. It helps keep track of the brackets in your code by cycling\nthrough a rainbow of colors, one for each pair of brackets. This makes it\ntrivial to spot the brackets and their corresponding opening and closing \nbrackets, and makes spotting the location of a missing closing bracket a piece\nof cake.\n\n{{\u003c figure src=\"https://i.stack.imgur.com/KuVtF.png\" title=\"Rainbow Brackets Example\" class=\"dark\"\u003e}}\n\n## Git Commit Template\n\n- [Plugin Page](https://plugins.jetbrains.com/plugin/9861-git-commit-template)\n\nIf you want to maintain a consistent style to your commits, according to a\n[Conventional Commit\nMessage](https://gist.github.com/qoomon/5dfcdf8eec66a051ecd85625518cfd13) style,\nthis plugin makes it easy to do so. The commit template used by this plugin is\nthe following:\n\n```html \n\u003ctype\u003e(\u003coptional scope\u003e): \u003csubject\u003e\n\u003cempty separator line\u003e\n\u003coptional body\u003e\n\u003cempty separator line\u003e\n\u003coptional footer\u003e\n```\ne.g.:\n```text\nfeat(jetbrains notes): added git commit template plugin\n```","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/kalman-filter":{"title":"Kalman Filter","content":"\n## Linearised Kalman filter\n\n## Extended Kalman filter\n\n- Non-linear filter\n- [Hidden Markov model](public/markov-models.md#hidden-markov-model)\n\n## Unscented Kalman filter\n\n- Non-linear filter\n\n$$\n\\begin{equation}\n    \\begin{aligned}\n        L                   \u0026= \\text{dim}(\\hat{\\mathbf{x}})                                                      \u0026\u0026 \\mathbf{x}\\in{\\mathbb{R}}^{L} \\\\\n        \\mathcal{X}_0       \u0026= \\hat{\\mathbf{x}} _{i-1}^{+}                                                                                     \\\\\n        \\mathcal{X}_j       \u0026= \\hat{\\mathbf{x}} _{i-1}^{+} + \\sqrt{(L+\\lambda)} \\mathbf{A}_j                         \u0026\u0026 j=1,...,L                 \\\\\n        \\mathcal{X} _{L+j}  \u0026= \\hat{\\mathbf{x}} _{i-1}^{+} - \\sqrt{(L+\\lambda)} \\mathbf{A}_j                         \u0026\u0026 j=1,...,L                 \\\\\n        W_0^{(m)}           \u0026= \\lambda(L-\\lambda)                                                                                         \\\\\n        W_0^{(c)}           \u0026= \\lambda(L-\\lambda) + (1-\\alpha^2 + \\beta)                                                                  \\\\\n        W_k^{(m)}           \u0026= W_k^{(c)} = 1/\\{2(L+\\lambda)\\}                                                \u0026\u0026 j=1,...,2L                \\\\\n    \\end{aligned}\n\\end{equation}\n$$\n\n$$\n\\begin{aligned}\n\\text{where  }\n    \\lambda \u0026= \\alpha^2(L+\\kappa)-L,\\text{ a scaling parameter,} \\\\\n    \\alpha  \u0026= \\text{parameter determining spread of sigma points about }\\hat{\\mathbf{x}}\\text{,} \\\\\n    \\kappa  \u0026= \\text{secondary scaling parameter, usually set to }0, \\\\\n    \\beta   \u0026= \\text{ parameter for incorporation of prior knowledge of }p(\\hat{\\mathbf{x}}).\\\\\n\\end{aligned}\n$$\n\n{{\u003c svg src=\"/public/images/sigma-points-wan.svg\" caption=\"Visual representation of sigma points, $\\mathcal{X}_j$, using Wan and van der Merwe's proposed parametrisation. $\\kappa=0$, $\\alpha=1$\" \u003e}}\n\n[comment]: \u003c\u003e ({{\u003c figure src=\"/public/images/sigma-points-wan.svg\" caption=\"Visual representation of sigma points, $\\mathcal{X}_j$, using Wan and van der Merwe's proposed method.\" \u003e}})\n\n\n## Discriminative Kalman filter\n\n- Non-linear filter\n\n## Inspiration for distillation\n\n- [How a Kalman filter works, in pictures](http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/)\n\n","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/least-squares":{"title":"Least Squares","content":"\nThe least-squares method, a method of solving overdetermined sets of linear\nequations, was officially discovered and published by Adrien-Marie Legendre in\ntheir work _\"Nouvelles methodes pour la determination des orbites des cometes\"_,\npublished in 1805.\n\n```bibtex {linenos=false}\n@Book{Legendre1805,\n    author = {Legendre, A. M.},\n    title = {Nouvelles methodes pour la determination des orbites des cometes [microform] / par A.M. Legendre},\n    publisher = {F. Didot Paris},\n    pages = {viii, 80 p., [1] leaf of plates :},\n    year = {1805},\n    type = {Book, Microform},\n    language = {French},\n    subjects = {Comets -- Orbits.},\n    life-dates = {1970 - 1805},\n    catalogue-url = {https://nla.gov.au/nla.cat-vn866184},\n}\n```\n\n## Ordinary Least Squares\n\nOrdinary Least Squares (OLS)\n\n$$\n\\begin{equation}\n    {\\hat {\\beta }}={\\rm {arg}}\\min _{\\beta }\\,\\lVert z-X\\beta \\rVert,\n\\end{equation}\n$$\n\n- **Linearity in parameters**: The system model is _linear in\n  parameters_, that is, $\\mathbf{z} = \\mathbf{A}\\mathbf{\\beta}+\\mathbf{\\epsilon}$.\n- **Strict exogenity**: The errors in the regression are should have conditional mean\n  zero, that is, $\\mathbb{E}[\\mathbf{\\epsilon}|\\mathbf{A}] = \\mathbf{0}$.\n\n{{\u003c svg src=\"/public/images/OLS-geometric-interpretation.svg\" caption=\"Geometric interpretation of Ordinary Least Squares (OLS).\" \u003e}}\n\n![[/public/images/OLS-geometric-interpretation.svg]]\n\n## Weighted Least Squares\n\nThe Weighted Least Squares (WLS) method is an application of the\nGeneralised Least Squares (GLS) algorithm, which aims at\nestimating unknown parameters ($\\mathbf{\\beta}$) in a linear regression model, given a\nset of observations ($\\mathbf{z}$), where there is a certain degree of correlation\n($\\mathbf{W}$) between the residuals ($\\mathbf{\\epsilon}$) in the regression model. It\nis usually written as:\n\n$$\n\\begin{equation}\n    \\begin{aligned}\n        \\mathbf{z} \u0026= \\mathbf{A}\\mathbf{\\beta}+\\mathbf{\\epsilon}, \\\\\n        \\mathbb{E}[\\mathbf{\\epsilon}|\\mathbf{A}] \u0026= \\mathbf{0}, \\\\\n        \\text{Cov}(\\mathbf{\\epsilon}|\\mathbf{A}) \u0026= \\mathbf{W}. \\\\\n    \\end{aligned}\n\\end{equation}\n$$\n\nThe residual vector is defined as $\\rho=\\mathbf{z}-\\mathbf{A}\\mathbf{\\beta}$. The Weighted\nLeast Squares estimate ($\\mathbf{\\hat{\\beta}}$) is unbiased, consistent and\nefficient, and obtained through minimising $\\mathbf{\\rho}^T\\mathbf{W}^{-1}\\mathbf{\\rho}$. The\nestimate is given, without derivation, by:\n\n$$\n\\begin{equation}\n    \\begin{aligned}\n        \\mathbf{\\hat{\\beta}} \u0026= (\\mathbf{A}^T\\mathbf{W}^{-1}\\mathbf{A})^{-1}\\mathbf{A}^T\\mathbf{W}^{-1}\\mathbf{z}, \\\\\n        \\mathbb{E}[\\mathbf{\\hat{\\beta}}] \u0026= \\mathbf{\\beta}, \\\\\n        \\text{Cov}[\\mathbf{\\hat{\\beta}}|\\mathbf{A}] \u0026= (\\mathbf{A}^T\\mathbf{W}^{-1}\\mathbf{A})^{-1}. \\\\\n    \\end{aligned}\n\\end{equation}\n$$\n\n## Generalised Least Squares\n\nGLS was first described by Alexander Aitken in 1936. \\[[1](https://en.wikipedia.org/wiki/Generalized_least_squares#cite_note-1)\\]\n\n## Non-linear Least Squares\n\nThe problem arises when considering the highly non-linear modelled measurements\n$\\mathbf{h}(\\mathbf{x}_0)$ cannot be described by the linear relation above. For this\nreason, the model is linearized by approximation to a first-order Taylor\npolynomial expansion about $\\mathbf{x}_0^k$, where $k$ is an iteration number:\n\n$$\n\\begin{equation}\n    \\begin{aligned}\n        \\mathbf{z}                              \u0026=        \\mathbf{f}(\\mathbf{\\beta}) + \\mathbf{\\epsilon}                                                              \\\\\n        \\mathbf{f}(\\mathbf{\\beta}+\\Delta\\mathbf{\\beta}) \u0026\\approx  \\mathbf{f}(\\mathbf{\\beta}) + \\frac{\\partial{\\mathbf{f}(\\mathbf{\\beta})}}{\\partial{\\mathbf{\\beta}}}\\Delta\\mathbf{\\beta}  \\\\\n    \\end{aligned}\n\\end{equation}\n$$\n","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/linear-algebra":{"title":"Linear Algebra","content":"\n## Definitions\n\n### (System of) Linear Equation(s)\n\nA system of linear equations may be represented as the matrix equation:\n\n$$\n\\mathbf{A}\\mathbf{x} = \\mathbf{b},\n$$\n\nand is equivalent to the following systems of linear equations:\n\n$$\n\\begin{aligned} \n    a_{1,1}x_{1} + a_{1,2}x_{2} + \u0026\\cdots + a_{1,n}x_{n} = b_{1} \\\\\n                                  \u0026\\ \\ \\vdots                    \\\\\n    a_{m,1}x_{1} + a_{m,2}x_{2} + \u0026\\cdots + a_{m,n}x_{n} = b_{m} \n\\end{aligned}\n$$\n\n## Matrix Decomposition\n- [[cholesky-decomposition |Cholesky Decomposition]]\n- [Singular Value Decomposition](notes/singular-value-decomposition.md)\n\n## Definitions\n\n- A symmetric matrix $\\mathbf{A}\\in\\mathbb{R}^{n\\times{n}}$ is positive semidefinite if:\n\n$$\n\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\geq 0 \\forall\\,\\mathbf{x} \\in\\mathbb{R}^n.\n$$\n\n- A symmetric matrix $\\mathbf{A}\\in\\mathbb{R}^{n\\times{n}}$ is positive definite if:\n\n$$\n\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\u003e 0 \\forall\\,\\mathbf{x}\\neq 0 \\in\\mathbb{R}^n.\n$$","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/machine-learning":{"title":"Machine Learning","content":"\n## Sub-fields\n- [Deep Learning](public/deep-learning.md)\n\n## Useful Topics\n- [Data Sampling Methods](public/data-sampling-methods.md)\n","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/markov-models":{"title":"Markov Models","content":"\n{{\u003c rawhtml \u003e}}\n\u003ctable class=\"tg\"\u003e\n\u003cthead\u003e\n  \u003ctr\u003e\n    \u003cth class=\"tg-fymr\"\u003eCharacterization\u003c/th\u003e\n    \u003cth class=\"tg-fymr\"\u003eFully Observable\u003c/th\u003e\n    \u003cth class=\"tg-fymr\"\u003ePartially Observable\u003c/th\u003e\n  \u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n  \u003ctr\u003e\n    \u003ctd class=\"tg-fymr\"\u003eAutonomous\u003c/td\u003e\n    \u003ctd class=\"tg-0pky\"\u003eMarkov chain/ process\u003c/td\u003e\n    \u003ctd class=\"tg-0pky\"\u003eHidden Markov model\u003c/td\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd class=\"tg-fymr\"\u003eControlled\u003c/td\u003e\n    \u003ctd class=\"tg-0pky\"\u003eMarkov decision process\u003cbr\u003e\u003c/td\u003e\n    \u003ctd class=\"tg-0pky\"\u003ePartially observable Markov decision process\u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n{{\u003c /rawhtml \u003e}}\n\n## Hidden Markov model\n\n### Markov chains and processes\n\n- A Markov chain is a discrete-time process.\n- A Markov process is a continuous-time process.\n","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/notes-website":{"title":"Quartz, Obsidian, and Hugo","content":"\n# Test \n\n```shell\nmkdir %USERPROFILE%/src\ncd %USERPROFILE%/src\ngit clone https://github.com/gohugoio/hugo.git\ncd hugo\ngo install --tags extended -v -x\n```\n","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/orbit-determination":{"title":"Orbit Determination and Parameter Estimation","content":"\nPredicting the state ($\\mathbf{x}_t$) of a spacecraft given an initial condition\n($\\mathbf{x}_0$), and models which form the equations of motion of the satellite,\n($\\dot{\\mathbf{x}}=f(t,\\mathbf{x})$), is a straightforward task involving the solution\nof an initial value problem (IVP) in the form of an ordinary differential\nequation (ODE). However the inverse problem  is more involved, that is, given a\nset of measurements ($\\mathbf{z}$) resulting from the dynamical system, we would\nlike to estimate the trajectory of the satellite and the parameters describing\nthe dynamical models, described mathematically as:\n\n$$\n\\begin{equation}\n    \\mathbf{x}(t) =\n    \\begin{bmatrix}\n        \\mathbf{r}(t) \\\\\n        \\mathbf{v}(t) \\\\\n        \\mathbf{p} \\\\\n        \\mathbf{q} \\\\\n    \\end{bmatrix},\n\\end{equation}\n$$\n\n$$\n\\begin{aligned}\n    \\textrm{where  }\n        \\mathbf{r}(t), \\mathbf{v}(t) \u0026= \\text{the position and velocity of the spacecraft as a function of time,} \\\\\n        \\mathbf{p}               \u0026= \\text{the parameters describing the force models,} \\\\\n        \\mathbf{q}               \u0026= \\text{the parameters describing the measurement models.} \\\\\n\\end{aligned}\n$$\n\nThe measurements made throughout the trajectory of the spacecraft at times\n$t_1,...,t_n$ are described by $\\mathbf{z}=[z_1,...,z_n]^T$, where each $z_i$ is\neither defined as a function of the state of the spacecraft at time $t_i$, or\nas a function of the state of the spacecraft at time $t_0$:\n\n$$\n\\begin{equation}\n    z_i(t_i) = g_i(t_i, \\mathbf{x}(t_i))+\\epsilon_i = h_i(t_i, \\mathbf{x}_0)+\\epsilon_i.\n\\end{equation}\n$$\n\n$$\n\\begin{aligned}\n    \\textrm{where  }\n        z_i \u0026= \\text{the i}^{th}\\text{ empirical measurement, assumed to be a random variable,} \\\\\n        g_i \u0026= \\text{the i}^{th}\\text{ model measurement as a function time and instantaneous state,} \\\\\n        h_i \u0026= \\text{the i}^{th}\\text{ model measurement as a function time and initial state,} \\\\\n        \\epsilon_i \u0026= \\text{the i}^{th}\\text{ residual, accounting for measurement errors.} \\\\\n\\end{aligned}\n$$\n\nThe expressions of $h_i$ and $g_i$ can be used interchangeably in the\nmeasurement model predictions, to account for the fact that the measurements are\noften made at different times than the respective instantaneous states of the\nspacecraft. This is done using variational equations, which are simulated to\nobtain the state transition matrix $\\mathbf{\\Phi}(t_0, t)$ of the spacecraft, which\nmay be interpolated for any arbitrary time within the temporal bounds of the ODE\nsolution across $t_i\\in[t_0, t_f]$, so that one may\nrelate an empirical $z_i$ at $\\mathbf{x}(t_i)$ to $\\mathbf{x}_0$ through $\\mathbf{\\Phi}(t_0,\nt_i)^{-1}\\mathbf{x}_0$. This effectively constrains the trajectory to the designed m\nIVP dynamical solution. Consequentially, the measurements concisely:\n\n$$\n\\begin{equation}\n    \\mathbf{z} = \\mathbf{h}(\\mathbf{x}_0) + \\mathbf{\\epsilon}.\n\\end{equation}\n$$\n","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/singular-value-decomposition":{"title":"","content":"","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/software-engineering":{"title":"Software Engineering","content":"## Algorithms\n- [Density-based spacial clustering of applications with noise (DBSCAN)](public/dbscan.md)\n\n## Object Oriented\n- [SOLID Principles](public/solid-principles.md)\n\n## Frontend\n- [Cascading Style Sheets (CSS)](public/css.md)\n- [Three.js (Web 3D Computer Graphics)](public/threejs.md)\n\n## Personalised Environments\n- [Windows Environments](public/windows-environment.md)\n- [Ubuntu Environment](public/ubuntu-environment.md)\n- [JetBrains Environment](public/jetbrains-environment.md)","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/solid-principles":{"title":"SOLID Principles","content":"\nIn software engineering, **SOLID** is a mnemonic acronym for five design\nprinciples intended to make object-oriented designs more **understandable**,\n**flexible**, and **maintainable**.\n\n## **S**ingle responsibility\n\n\u003e There should never be more than one reason for a class to change.\n\n## **O**pen‚Äìclosed\n\n\u003e Software entities ... should be open for extension, but closed for modification.\n\n## **L**iskov substitution\n\n\u003e Functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it.\n\n## **I**nterface segregation\n\n\u003e Many client-specific interfaces are better than one general-purpose interface.\n\n## **D**ependency inversion\n\n\u003e Depend upon abstractions, \\[not\\] concretions.","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/threejs":{"title":"Three.js Fundamentals","content":"\nThree.js is a cross-browser Javascript API which allows for the creation and\ndisplay of 3D computer graphics in a web browser built on top of\n[WebGL](https://en.wikipedia.org/wiki/WebGL?wprov=sfla1), a lower level\nJavascript API allowing for GPU-accelerated physics and image processing\nlocally, as part of the web page canvas.\n\n{{\u003c rawhtml \u003e}}\n\u003cdiv class=\"threejs\" id=\"threejs-cube\"\u003e\u003c/div\u003e\n{{\u003c /rawhtml \u003e}}\n\nThere exists a [plethora of examples](https://threejs.org/) which can be used as\nstarting points in your projects, one of which I often encounter when [signing\ninto GitHub](https://github.com/home). Another personal favourite of mine is\nSpaceX's simulator which demonstrates the [**actual\ninterface**](https://iss-sim.spacex.com/) used by NASA Astronauts to manually\npilot the SpaceX Dragon 2 spacecraft to the International Space Station (ISS).\n\n\n\n````html {title=\"/index.html\"}\n\u003c!DOCTYPE html\u003e\n\u003chtml\u003e\n\u003chead\u003e\n    \u003cmeta charset=\"utf-8\"\u003e\n    \u003ctitle\u003eMy first three.js app\u003c/title\u003e\n    \u003cstyle\u003e body {\n        margin: 0;\n    } \u003c/style\u003e\n    \u003clink rel=\"stylesheet\" href=\"style.css\"\u003e\n    \u003cscript src=\"first-cube.js\" type=\"module\"\u003e\u003c/script\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cdiv id=\"threejs\"\u003e\u003c/div\u003e\n\u003c/body\u003e\n````\n\nThe main components of any `three.js` app are the scene, the camera, and the\nrenderer. These are setup as demonstrated in the following code:\n\n````javascript {linenos=true, linenostart=5, title=\"/first-cube.js\"}\n// 0. Get your desired element to render on\nlet element = document.getElementById('threejs');\nlet w = window.innerWidth;\nlet h = window.innerHeight;\n\n// 1. Create a scene\nvar scene = new THREE.Scene();\n\n// 2. Create a camera\nlet camera = new THREE.PerspectiveCamera(\n    75, w / h, 0.1, 1000);\n\n// 3. Create a render\nvar renderer = new THREE.WebGLRenderer();\n\n// 4. Set the size of the render\nrenderer.setSize(w, h);\n````\n\n- There are different types of cameras in `three.js`:\n- [PerspectiveCamera](https://threejs.org/docs/#api/cameras/PerspectiveCamera)\n- [OrthographicCamera](https://threejs.org/docs/#api/cameras/OrthographicCamera)\n- [CubeCamera](https://threejs.org/docs/#api/cameras/CubeCamera)\n- [StereoCamera](https://threejs.org/docs/#api/cameras/StereoCamera)\n- [ArrayCamera](https://threejs.org/docs/#api/cameras/ArrayCamera)\n- [Camera](https://threejs.org/docs/#api/cameras/Camera)\n\nBut for now, we'll stick with the PerspectiveCamera.\n\n`PerspectiveCamera(fov, aspect, near, far)`\n\n- `near`: The near clipping plane. Nothing is rendered before this distance.\n- `far`: The far clipping plane. Nothing is rendered after this distance.\n- `fov`: The field of view.\n- `aspect`: The aspect ratio.\n\n**Want to render at a different resolution?** \n\u003e Use the `setSize` method. If you wish to keep the size of your app but render\nit at a lower resolution, you can do so by calling setSize with false as\nupdateStyle (the third argument). For example, `setSize(window.innerWidth/2,\nwindow.innerHeight/2, false)` will render your app at half resolution, given\nthat your `\u003ccanvas\u003e` has 100% width and height.\n\nLet's add a cube to our scene.\n````js {linenos=false}\nconst geometry = new THREE.BoxGeometry(1, 1, 1);\nconst material = new THREE.MeshBasicMaterial({color: 0x00ff00});\nconst cube = new THREE.Mesh(geometry, material);\nscene.add(cube);\ncamera.position.z = 5;\n````\n\n\u003e By default, when we call scene.add(), the thing we add will be added to the\ncoordinates (0,0,0). This would cause both the camera and the cube to be inside\neach other. To avoid this, we simply move the camera out a bit.\n\n**Rendering the scene**\n\n\u003e If you copied the code from above into the HTML file we created earlier, you\nwouldn't be able to see anything. This is because we're not actually rendering\nanything yet. For that, we need what's called a render or animate loop.\n\n\n### Resources\n\n- [Using Three.js to Add 3D Elements to your Websites](https://www.elegantthemes.com/blog/design/using-three-js-to-add-3d-elements-to-your-websites)","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/typescript":{"title":"TypeScript","content":"\nSome links I'm collecting:\n- [Get Started With Typescript in 2019](https://robertcooper.me/post/get-started-with-typescript-in-2019)","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/ubuntu-environment":{"title":"Ubuntu Environment","content":"\n- Last carried out with `Ubuntu 20.0.4`\n\n\n## General\n\n### Install `htop`\n\n```bash\nsudo apt-get install htop \n```\n\n### Install `git`\n\n```bash\nsudo apt-get install git \n```\n\n### Install build tools\n\n```bash\nsudo apt-get install build-essential\n```\n\n### Connect to your Android or Apple devices\n\n1. Install the \"KDE Connect\" app on your mobile device from its respective app store, whether it's\n[Apple iOS](https://apps.apple.com/us/app/kde-connect/id1580245991) or [Android](https://play.google.com/store/apps/details?id=org.kde.kdeconnect_tp\u0026hl=en_ZA\u0026gl=US)\n\n2. If you're using gnome, install `GSConnect` via the [gnome extensions](https://extensions.gnome.org/extension/1319/gsconnect/), otherwise `KDE Connect` via `apt` (you will probably be using the commandline interface for the latter.\n\n```bash\nsudo apt install kdeconnect\n```\n\n3. Configure GSConnect (Under mobile devices) on the taskbar of Ubuntu, ensure both devices are on the same network, select the device, and `Request pair`. I haven't used `KDE Connect`, so I don't provide any info here on that.\n\n4. Accpet the pair request on your mobile device.\n\nYou can now access the following functions/features on your Ubuntu task bar, relating to your mobile device:\n- `Battery \u003cStatus\u003e`\n- `Browse device`\n- `Ring device`\n- `Send file`\n- `SMS Messages...`\n\n\n## Setting up with an NVIDIA GPU\n\n### Select appropriate drivers\n\nIf immediately after installation, you have some display issues, it's likely\nthat a display driver hasn't been selected as was the case with me on my desktop.\nEnsure latest `(proprietary, tested)` drivers used for NVIDIA GPU in `Software \u0026 Updates \u003e Additional Drivers`\n\n### Configure high refresh rates\n\nCan be set (if defaults aren't correct) through:\n\n```bash\nnvidia-settings\n```\nIf you're using multiple monitors, one at 60 Hz and another at 144 Hz (for example),\nyou might notice that dragging a window around on the 144 Hz monitor will render\nin 60 Hz, however your cursor will render at 144 Hz. This has to do with the \n\"display server\" used. `X.org` is used by default with nvidia, however Wayland needs to be \nused to properly support mixed refresh rate monitors, however there is limited support of Wayland by nvidia.\n*If* your nvidia driver supports it:\n\n1. Edit `/etc/gdm3/custom.conf` and set `WaylandEnable=true`\n2. [Comment out the lines mentioned here](https://askubuntu.com/questions/1403854/cant-use-wayland-with-nvidia-510-drivers-on-ubuntu-22-04-lts)\n\n*Note*: This worked for my NVIDIA 1080 TI with the NVIDIA 510 drivers, using\na 60 Hz 4k monitor with a G-SYNC 144 Hz. I have yet to encounter any \nundesirable consequences, but will add it here if I do.\n\n### Problem: Login screen is not on primary monitor\n\n```bash\nsudo cp ~/.config/monitors.xml ~gdm/.config/monitors.xml\n```\n\n### How to: Check Card Model\n\n```bash\nlspci | grap VGA\n```\n\n\n## Installing LaTeX\n\n- texlive-base ‚Äì 160 MB\n- texlive-latex-recommended ‚Äì 203 MB\n- texlive ‚Äì 269 MB\n- texlive-latex-extra ‚Äì 464 MB\n- texlive-full ‚Äì 5903 MB\n\n\n### Install everything\n```bash\n sudo apt install texlive-full -y  # 5903 MB\n```\n\n\n### Install M.Sc. thesis dependencies\n```bash\nsudo apt install texlive-latex-extra  # 464 MB\n```\n#### Xelatex\n\n- missing `xelatex` ?\n\n```bash\nsudo apt-get install texlive-xetex  # 18.4 MB \n```\n#### Science packages\n\n- missing `physics.sty` ?\n\n```bash\nsudo apt-get install texlive-science  # 115 MB \n```\n\n#### Math fonts\n\n- missing `mathabx.sty` ?\n\n```bash\nsudo apt-get install texlive-fonts-extra  # 1,383 MB\n```\n\n#### BibLaTeX\n\n- ([src](https://tex.stackexchange.com/questions/102817/setting-up-texmaker-on-ubuntu-biblatex-sty-not-found)) missing `bibtex.sty` ?\n\n\n```bash\nsudo apt-get install texlive-bibtex-extra biber  # 118 MB\n```\n\n## Customizing Terminal\n\n## I want `Fn` keys as non-default\n\nAs mentioned [here](https://www.hashbangcode.com/article/turning-or-fn-mode-ubuntu-linux),\nI fixed this for my Keychron keyboard with:\n\n**Temporary**\n```bash\necho 2 | sudo tee /sys/module/hid_apple/parameters/fnmode\n```\n\n**Permanent**\n\n```bash\necho options hid_apple fnmode=2 | sudo tee -a /etc/modprobe.d/hid_apple.conf\n```\n```bash\nsudo update-initramfs -u -k all \n```\n\n\n## Installing PyCharm\n\nVisit Jetbrains [download link](https://www.jetbrains.com/pycharm/download/) or\nuse `Ubuntu Software`.\n\n","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null},"/public/windows-environment":{"title":"Windows Environment","content":"\n\n- [Setting up Windows Terminal, WSL and Oh-my-Zsh](https://www.ivaylopavlov.com/setting-up-windows-terminal-wsl-and-oh-my-zsh/#.YrHoEVTMKh9)","lastmodified":"2022-06-29T09:30:38.980113444Z","tags":null}}